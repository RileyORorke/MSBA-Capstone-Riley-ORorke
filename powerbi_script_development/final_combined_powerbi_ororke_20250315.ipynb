{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power BI Integration: Generating Bore Size Predictions  \n",
    "\n",
    "The purpose of this code is to prepare the dataset for use within Power BI by importing data, processing it, and generating predictions for future bore sizes along with wear classifications using a Random Forest Regressor model. The final output is a dataset containing both actual and predicted bore sizes for future cycles, which can be visualized and analyzed within Power BI. Below is an overview of the steps performed in the script:\n",
    "\n",
    "---\n",
    "\n",
    "#### Data Import and Preprocessing:\n",
    "1. **Load Dataset**: The dataset is loaded directly from Power BI and stored in the `df` variable. This ensures that the data is accessible for subsequent analysis.\n",
    "2. **Drop Unnecessary Columns**: The script removes columns that are not relevant for the analysis. This simplifies the dataset and eliminates clutter, ensuring that only the necessary features are used in the modeling process.\n",
    "3. **Data Type Conversion**: Measurement values (`\"C.[DataValue]\"`) are converted to numeric types, and timestamps (`\"C.[EntryTimestamp]\"`) are converted to `datetime` objects. This allows for more precise data handling and analysis.\n",
    "4. **Outlier Removal Using IQR**: Outliers in the data are removed using the Interquartile Range (IQR) method, ensuring that extreme values do not distort the model's performance.\n",
    "\n",
    "---\n",
    "\n",
    "#### Feature Engineering:\n",
    "1. **Lag Features**: The script creates lag features for different time windows (3, 5, 10, 15, 20 cycles) to capture the temporal dependencies of bore measurements.\n",
    "2. **Rolling Statistics**: Rolling mean and standard deviation are computed for multiple time windows (3, 5, 10 cycles) to capture short-term trends in the bore measurements.\n",
    "3. **Cycle Count**: A `Cycle_Count` column is created to track the cycle number for each measurement.\n",
    "4. **Target Variable**: The target variable, `\"Target_NextCycle\"`, is defined by shifting the bore measurements by one cycle, allowing for the prediction of future bore sizes.\n",
    "\n",
    "---\n",
    "\n",
    "#### Model Training:\n",
    "1. **Random Forest Regressor**: A Random Forest Regressor is trained on the features (`rfr_features`) to predict the target variable, `\"Target_NextCycle\"`. Hyperparameters such as `n_estimators=200`, `max_depth=10`, and others are specified to optimize the model's performance.\n",
    "2. **Model Fitting**: The model is trained on the training data (`X_train`, `y_train`) to learn patterns and relationships in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "#### Future Bore Size Predictions:\n",
    "1. **Future Cycles**: The number of future cycles to predict (`future_cycles`) is specified. In this case, predictions are made for 10 future cycles, but this can be adjusted as needed.\n",
    "2. **Prediction Loop**: The script uses the last known values from the dataset to predict future bore sizes by iteratively applying the model and updating the rolling statistics for each cycle.\n",
    "3. **Wear Classification**: Based on the predicted changes in bore size, the wear stage for each future cycle is classified as either **Normal Wear**, **Moderate Wear**, or **Critical Wear**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Merging Actual and Predicted Data:\n",
    "1. **Combine Data**: The script merges the actual and predicted data into a final dataset (`final_df`), which includes both the original bore measurements and the predicted values for future cycles along with the associated wear classifications.\n",
    "2. **Power BI Integration**: The final dataset is displayed as the output, which can be directly imported into Power BI for further analysis and visualization.\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Considerations:\n",
    "1. **Adjustable Parameters**: \n",
    "   - **Number of Future Cycles**: The number of future cycles for which predictions are made can be adjusted by changing the `future_cycles` variable.\n",
    "   - **Wear Classification Cutoffs**: The thresholds used to classify wear stages (e.g., `Normal Wear`, `Moderate Wear`, and `Critical Wear`) can be customized to suit different operational definitions or requirements.\n",
    "2. **Feature Engineering**: The lag features and rolling statistics windows can be adjusted to capture more or less historical information, depending on the characteristics of the data and the needs of the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load dataset from Power BI (or from SQL if used in Power BI)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m  \u001b[38;5;66;03m# Power BI automatically loads data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Drop unnecessary columns\u001b[39;00m\n\u001b[0;32m     13\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD.[NamePostfix]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF.[Name]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG1.[ParameterID]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG1.[Name]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG1.[OperatorMessage]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG2.[ParameterID]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG2.[Name]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG2.[Description]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG3.[ParameterID]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG3.[Name]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB.[Description]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC.[ParameterID]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m ]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load dataset from Power BI\n",
    "df = dataset.copy()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    \"D.[NamePostfix]\", \"F.[Name]\", \"G1.[ParameterID]\", \"G1.[Name]\",\n",
    "    \"G1.[OperatorMessage]\", \"G2.[ParameterID]\", \"G2.[Name]\", \n",
    "    \"G2.[Description]\", \"G3.[ParameterID]\", \"G3.[Name]\", \n",
    "    \"G3.[OperatorMessage]\", \"A.[ParameterID]\", \"A.[EntryTimestamp]\", \n",
    "    \"A.[DataValue]\", \"A.[Description]\", \"B.[ParameterID]\", \n",
    "    \"B.[EntryTimestamp]\", \"B.[DataValue]\", \"B.[Description]\", \n",
    "    \"C.[ParameterID]\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns], \n",
    "             errors=\"ignore\")\n",
    "\n",
    "# Convert measurement values to numeric\n",
    "df[\"C.[DataValue]\"] = pd.to_numeric(df[\"C.[DataValue]\"], errors=\"coerce\")\n",
    "\n",
    "# Convert timestamps to datetime and sort\n",
    "df[\"C.[EntryTimestamp]\"] = pd.to_datetime(df[\"C.[EntryTimestamp]\"], \n",
    "                                          errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"C.[EntryTimestamp]\"]).sort_values(\n",
    "    by=\"C.[EntryTimestamp]\"\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Outlier Removal Using IQR\n",
    "Q1 = df[\"C.[DataValue]\"].quantile(0.25)\n",
    "Q3 = df[\"C.[DataValue]\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[\n",
    "    (df[\"C.[DataValue]\"] >= lower_bound) & \n",
    "    (df[\"C.[DataValue]\"] <= upper_bound)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Create Lag Features\n",
    "for lag in [3, 5, 10, 15, 20]:\n",
    "    df[f\"DataValue_Lag{lag}\"] = df[\"C.[DataValue]\"].shift(lag)\n",
    "\n",
    "# Create Rolling Statistics\n",
    "for window in [3, 5, 10]:\n",
    "    df[f\"Rolling_Mean_{window}\"] = df[\"C.[DataValue]\"].rolling(\n",
    "        window=window\n",
    "    ).mean()\n",
    "    df[f\"Rolling_Std_{window}\"] = df[\"C.[DataValue]\"].rolling(\n",
    "        window=window\n",
    "    ).std()\n",
    "\n",
    "# Create Cycle Count\n",
    "df[\"Cycle_Count\"] = np.arange(1, len(df) + 1)\n",
    "\n",
    "# Define target variable\n",
    "df[\"Target_NextCycle\"] = df[\"C.[DataValue]\"].shift(-1)\n",
    "\n",
    "# Drop NaN values due to shifting\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = [\n",
    "    \"Cycle_Count\", \"C.[DataValue]\", \"DataValue_Lag3\", \"DataValue_Lag5\", \n",
    "    \"DataValue_Lag10\", \"DataValue_Lag15\", \"DataValue_Lag20\", \n",
    "    \"Rolling_Mean_3\", \"Rolling_Std_3\", \"Rolling_Mean_5\", \"Rolling_Std_5\", \n",
    "    \"Rolling_Mean_10\", \"Rolling_Std_10\"\n",
    "]\n",
    "\n",
    "# Train Random Forest Model\n",
    "X = df[feature_columns]\n",
    "y = df[\"Target_NextCycle\"]\n",
    "\n",
    "rfr_model = RandomForestRegressor(\n",
    "    n_estimators=200,        \n",
    "    max_depth=10,            \n",
    "    min_samples_split=10,    \n",
    "    min_samples_leaf=5,       \n",
    "    max_features=\"sqrt\",     \n",
    "    bootstrap=True,          \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rfr_model.fit(X, y)\n",
    "\n",
    "# Define how many future cycles to predict\n",
    "future_cycles = 10  \n",
    "\n",
    "# Create a DataFrame for future predictions\n",
    "future_df = pd.DataFrame()\n",
    "future_df[\"Cycle_Count\"] = range(\n",
    "    df[\"Cycle_Count\"].max() + 1, df[\"Cycle_Count\"].max() + 1 + future_cycles\n",
    ")\n",
    "\n",
    "# Use last known values for predictions\n",
    "last_known_values = df.iloc[-1][feature_columns].to_dict()\n",
    "predicted_bores = []\n",
    "\n",
    "# Predict future bore sizes using the trained model\n",
    "for cycle in future_df[\"Cycle_Count\"]:\n",
    "    new_row = last_known_values.copy()\n",
    "\n",
    "    # Shift lag values forward\n",
    "    for lag in [3, 5, 10, 15, 20]:\n",
    "        new_row[f\"DataValue_Lag{lag}\"] = (\n",
    "            predicted_bores[-lag] if len(predicted_bores) >= lag\n",
    "            else last_known_values[\"C.[DataValue]\"]\n",
    "        )\n",
    "\n",
    "    # Update rolling statistics dynamically\n",
    "    for window in [3, 5, 10]:\n",
    "        new_row[f\"Rolling_Mean_{window}\"] = (\n",
    "            np.mean(predicted_bores[-window:])\n",
    "            if len(predicted_bores) >= window\n",
    "            else last_known_values[f\"Rolling_Mean_{window}\"]\n",
    "        )\n",
    "        new_row[f\"Rolling_Std_{window}\"] = (\n",
    "            np.std(predicted_bores[-window:])\n",
    "            if len(predicted_bores) >= window\n",
    "            else last_known_values[f\"Rolling_Std_{window}\"]\n",
    "        )\n",
    "\n",
    "    # Convert to DataFrame and predict bore size\n",
    "    new_X = pd.DataFrame([new_row])[feature_columns]\n",
    "    predicted_bore = rfr_model.predict(new_X)[0]\n",
    "    predicted_bores.append(predicted_bore)\n",
    "\n",
    "    # Store predictions in the DataFrame\n",
    "    future_df.loc[future_df[\"Cycle_Count\"] == cycle, \"Predicted_Bore_Size\"] = (\n",
    "        predicted_bore\n",
    "    )\n",
    "\n",
    "# Compute bore size changes over time\n",
    "future_df[\"Bore_Size_Change\"] = future_df[\"Predicted_Bore_Size\"].diff().fillna(0)\n",
    "\n",
    "# Define wear classification function\n",
    "def classify_wear(change):\n",
    "    \"\"\"Classify wear stages based on bore size change.\"\"\"\n",
    "    if change < 0.001:\n",
    "        return \"Normal Wear\"\n",
    "    elif 0.001 <= change < 0.005:\n",
    "        return \"Moderate Wear\"\n",
    "    return \"Critical Wear\"\n",
    "\n",
    "# Assign wear labels to future cycles\n",
    "future_df[\"Predicted_Wear_Stage\"] = future_df[\"Bore_Size_Change\"].apply(\n",
    "    classify_wear\n",
    ")\n",
    "\n",
    "# Merge actual and predicted data\n",
    "df[\"Predicted_Bore_Size\"] = np.nan\n",
    "df[\"Predicted_Wear_Stage\"] = np.nan\n",
    "\n",
    "# Final dataset\n",
    "final_df = pd.concat([df, future_df], ignore_index=True)\n",
    "\n",
    "# Display the final dataset for Power BI\n",
    "final_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
