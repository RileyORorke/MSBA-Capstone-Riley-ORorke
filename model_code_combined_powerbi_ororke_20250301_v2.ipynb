{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load dataset from Power BI (or from SQL if used in Power BI)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m  \u001b[38;5;66;03m# Power BI automatically loads data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Drop unnecessary columns\u001b[39;00m\n\u001b[0;32m     13\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD.[NamePostfix]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF.[Name]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG1.[ParameterID]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG1.[Name]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG1.[OperatorMessage]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG2.[ParameterID]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG2.[Name]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG2.[Description]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG3.[ParameterID]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG3.[Name]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB.[Description]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC.[ParameterID]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m ]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Power BI Python Script for Bore Size Prediction\n",
    "Using Random Forest Regression\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load dataset from Power BI\n",
    "df = dataset  \n",
    "\n",
    "# Drop unnecessary columns if they exist\n",
    "columns_to_drop = [\n",
    "    \"D.[NamePostfix]\", \"F.[Name]\", \"G1.[ParameterID]\", \"G1.[Name]\", \n",
    "    \"G1.[OperatorMessage]\", \"G2.[ParameterID]\", \"G2.[Name]\", \"G2.[Description]\", \n",
    "    \"G3.[ParameterID]\", \"G3.[Name]\", \"G3.[OperatorMessage]\", \"A.[ParameterID]\", \n",
    "    \"A.[EntryTimestamp]\", \"A.[DataValue]\", \"A.[Description]\", \"B.[ParameterID]\", \n",
    "    \"B.[EntryTimestamp]\", \"B.[DataValue]\", \"B.[Description]\", \"C.[ParameterID]\"\n",
    "]\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns], \n",
    "             errors=\"ignore\")\n",
    "\n",
    "# Convert measurement values to numeric\n",
    "df[\"C.[DataValue]\"] = pd.to_numeric(df[\"C.[DataValue]\"], errors=\"coerce\")\n",
    "\n",
    "# Convert timestamps to datetime and sort\n",
    "df[\"C.[EntryTimestamp]\"] = pd.to_datetime(df[\"C.[EntryTimestamp]\"], \n",
    "                                          errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"C.[EntryTimestamp]\"]).sort_values(\n",
    "    by=\"C.[EntryTimestamp]\"\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Outlier Removal Using IQR\n",
    "q1 = df[\"C.[DataValue]\"].quantile(0.25)\n",
    "q3 = df[\"C.[DataValue]\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "df = df[(df[\"C.[DataValue]\"] >= lower_bound) & \n",
    "        (df[\"C.[DataValue]\"] <= upper_bound)].reset_index(drop=True)\n",
    "\n",
    "# Create Lag Features (Updated to match model)\n",
    "for lag in [3, 5]:\n",
    "    df[f\"DataValue_Lag{lag}\"] = df[\"C.[DataValue]\"].shift(lag)\n",
    "\n",
    "# Create Rolling Statistics\n",
    "df[\"Rolling_Mean_3\"] = df[\"C.[DataValue]\"].rolling(window=3).mean()\n",
    "df[\"Rolling_Std_3\"] = df[\"C.[DataValue]\"].rolling(window=3).std()\n",
    "df[\"Rolling_Mean_5\"] = df[\"C.[DataValue]\"].rolling(window=5).mean()\n",
    "df[\"Rolling_Std_5\"] = df[\"C.[DataValue]\"].rolling(window=5).std()\n",
    "\n",
    "# Drop rows with NaN values (due to shifting)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Create a Cycle Count\n",
    "df[\"Cycle_Count\"] = range(1, len(df) + 1)\n",
    "\n",
    "# Define feature columns (Updated)\n",
    "feature_columns = [\n",
    "    \"Cycle_Count\", \"C.[DataValue]\", \"DataValue_Lag3\", \"DataValue_Lag5\",\n",
    "    \"Rolling_Mean_3\", \"Rolling_Std_3\", \"Rolling_Mean_5\", \"Rolling_Std_5\"\n",
    "]\n",
    "\n",
    "# Define target variable and drop last row to avoid NaN target\n",
    "df[\"Target_NextCycle\"] = df[\"C.[DataValue]\"].shift(-1)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Train a Random Forest Regressor (Updated Hyperparameters)\n",
    "X = df[feature_columns]\n",
    "y = df[\"Target_NextCycle\"]\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=40,\n",
    "    max_depth=5,\n",
    "    min_samples_split=15,\n",
    "    min_samples_leaf=7,\n",
    "    max_features=\"sqrt\",\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# Define how many future cycles to predict\n",
    "future_cycles = 10  # Adjust as needed\n",
    "\n",
    "# Create a DataFrame for future predictions\n",
    "future_df = pd.DataFrame()\n",
    "future_df[\"Cycle_Count\"] = range(df[\"Cycle_Count\"].max() + 1, \n",
    "                                 df[\"Cycle_Count\"].max() + 1 + future_cycles)\n",
    "\n",
    "# Use the last known values as the starting point for predictions\n",
    "last_known_values = df.iloc[-1][feature_columns].to_dict()\n",
    "predicted_bores = []\n",
    "\n",
    "\n",
    "def update_rolling_stats(predictions, last_values, window):\n",
    "    \"\"\"Update rolling mean and std dynamically for new predictions.\"\"\"\n",
    "    if len(predictions) >= window:\n",
    "        return np.mean(predictions[-window:]), np.std(predictions[-window:])\n",
    "    return last_values[f\"Rolling_Mean_{window}\"], last_values[f\"Rolling_Std_{window}\"]\n",
    "\n",
    "\n",
    "# Predict future bore sizes using the trained regression model\n",
    "for cycle in future_df[\"Cycle_Count\"]:\n",
    "    new_row = last_known_values.copy()\n",
    "    new_row[\"Cycle_Count\"] = cycle\n",
    "\n",
    "    # Shift lag values forward\n",
    "    for lag in [3, 5]:\n",
    "        new_row[f\"DataValue_Lag{lag}\"] = (\n",
    "            predicted_bores[-lag] if len(predicted_bores) >= lag \n",
    "            else last_known_values[\"C.[DataValue]\"]\n",
    "        )\n",
    "\n",
    "    # Update rolling statistics dynamically\n",
    "    new_row[\"Rolling_Mean_3\"], new_row[\"Rolling_Std_3\"] = update_rolling_stats(\n",
    "        predicted_bores, last_known_values, 3\n",
    "    )\n",
    "    new_row[\"Rolling_Mean_5\"], new_row[\"Rolling_Std_5\"] = update_rolling_stats(\n",
    "        predicted_bores, last_known_values, 5\n",
    "    )\n",
    "\n",
    "    # Convert to DataFrame and predict bore size\n",
    "    new_X = pd.DataFrame([new_row])[feature_columns]\n",
    "    predicted_bore = model.predict(new_X)[0]\n",
    "    predicted_bores.append(predicted_bore)\n",
    "\n",
    "    # Store new row values for further processing\n",
    "    future_df.loc[future_df[\"Cycle_Count\"] == cycle, \n",
    "                  \"Predicted_Bore_Size\"] = predicted_bore\n",
    "\n",
    "# Compute bore size changes over time\n",
    "future_df[\"Bore_Size_Change\"] = future_df[\"Predicted_Bore_Size\"].diff().fillna(0)\n",
    "\n",
    "\n",
    "def classify_wear(change):\n",
    "    \"\"\"Classify wear stages based on bore size change.\"\"\"\n",
    "    if change < 0.001:\n",
    "        return \"Normal Wear\"\n",
    "    if 0.001 <= change < 0.005:\n",
    "        return \"Moderate Wear\"\n",
    "    return \"Critical Wear\"\n",
    "\n",
    "\n",
    "# Assign wear labels to future cycles\n",
    "future_df[\"Predicted_Wear_Stage\"] = future_df[\"Bore_Size_Change\"].apply(classify_wear)\n",
    "\n",
    "# Combine actual & future data\n",
    "df[\"Predicted_Bore_Size\"] = np.nan  # Set actual cycles to NaN in prediction column\n",
    "df[\"Predicted_Wear_Stage\"] = np.nan\n",
    "\n",
    "# Final dataset\n",
    "final_df = pd.concat([df, future_df], ignore_index=True)\n",
    "\n",
    "final_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
